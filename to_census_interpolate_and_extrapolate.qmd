---
title: "Interpolation, Extrapolation, and Geometry Merging for Panel Data"
format: html
editor: visual
---

```{r setup}
# Set working directory 
setwd("/Users/taylordomingos/Documents/research_projects/second_year_paper/coding_files")

#Load necessary packages
library(pacman)
pload(cancensus, sf, geojsonsf, curl, httr, tidyverse, dplyr, Hmisc, zoo)

#Read in SF panel data
panel_data_6year <- st_read("/Users/taylordomingos/Documents/research_projects/second_year_paper/raw_data/panel_data.geojson")
```

## Interpolation, Extrapolation, and Geometry Merging for Panel Data

The function for interpolation and extrapolation using smoothing splines fills in missing data for each numeric column in the dataset by estimating values based on the available data for each group (grouped by tract_num and year). Here is documentation for the splinefun which I use below: "Perform cubic (or Hermite) spline interpolation of given data points, returning either a list of points obtained by the interpolation or a function performing the interpolation." https://rdrr.io/r/stats/splinefun.html and https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/splinefun

Cubic splines improve linear interpolation estimates in several cases because it essentially draws smoother curves over the estimates/data points. Cubic splines use a curve that smoothly connects data points, using a function that is a polynomial of degree three. The 'natural' part makes a smooth transition at the boundaries of your data, making the curve look natural at the ends.Linear interp basically estimates values between known data points by connecting them with sharp and straight lines, which may not represent the true trend. 'Natural' refers to the specific boundary condition used at the beginning and end of the data. By using the 'natural' curve it is setting the second derivative (concavity) to zero at the start and end points, the natural cubic spline avoids sharp bends or changes at the edges of the data.

Any extrapolated values are capped at zero to prevent unrealistic negative values. Similarly, percentage variables are capped at 100 percent.

```{r}
# Create a vector of all years you want in the expanded grid (1992-2020)
all_years <- 1992:2021

# Convert 'geouid_21' to character class
panel_data_6year$geouid_21 <- as.character(panel_data_6year$geouid_21)

# Create a dataframe with all of the possible combinations of 'geouid_21' (tract number) and year
template_df <- expand.grid(geouid_21 = unique(panel_data_6year$geouid_21), year = all_years)

# Merge the dataframe with original dataset
template_df <- template_df %>%
  mutate(year = as.character(year))

panel_data_6year <- panel_data_6year %>%
  mutate(year = as.character(year))

merged_data <- template_df %>%
  left_join(panel_data_6year, by = c("geouid_21", "year")) %>%
  arrange(geouid_21, year)

# This is a function to interpolate and extrapolate using smoothing splines
interpolate_and_extrapolate <- function(group_data) {
    # Define the range of years for which we want to perform the interpolation and extrapolation
    years_range <- seq(1992, 2020)
    
    # Apply smoothing splines for each column you want to interpolate and extrapolate
    group_data <- group_data %>%
        mutate(across(where(is.numeric), ~ {
            # Remove NAs and keep track of original data
            non_na_data <- na.omit(data.frame(year = group_data$year, value = .x))
            
            # If there are at least two data points (non-NA) available, it applies smoothing splines using splinefun with a natural cubic spline method. This creates a function (spline_func) that can estimate values for the given range of years.
            if (nrow(non_na_data) >= 2) {
                spline_func <- splinefun(non_na_data$year, non_na_data$value, method = "natural")
                spline_values <- spline_func(years_range)
                
                # Cap the extrapolated values at zero
                spline_values <- pmax(spline_values, 0)
                
                # Return estimated values in dataset with the result of the spline interpolation/extrapolation function
                result <- sapply(group_data$year, function(year) {
                    if (year %in% years_range) {
                        return(spline_values[which(years_range == year)])
                    }
                    return(.x) # Return original value otherwise
                })
                
                return(result)
            } else {
                # Uses the spline function to replace the data in the dataset. If the year is within the range, it uses the estimated value; otherwise, it keeps the original value.
                return(.x)
            }
        }))
    
    return(group_data)
}

# Group the data by `geouid_21` and apply the function above
result_data <- merged_data %>%
    group_by(geouid_21) %>%
    group_modify(~ interpolate_and_extrapolate(.))

# Ungroup the data frame
result_data <- result_data %>%
    ungroup()

# Convert all of my columns to numeric
result_data <- result_data %>%
  mutate(across(everything(), ~ as.numeric(as.character(.))))

# Round all numeric columns to two decimal places
result_data <- result_data %>%
    mutate(across(where(is.numeric), round, 2))

# Filter panel_data_6year for the year 1996
geometry_1996 <- panel_data_6year %>%
    filter(year == 1996) %>%
    dplyr::select(geouid_21, geometry)

# Merge the geometry from 1996 into result_data
# Convert geouid_21 in geometry_1996 to match the type in result_data
geometry_1996$geouid_21 <- as.numeric(geometry_1996$geouid_21)

result_data <- result_data %>%
    left_join(geometry_1996, by = "geouid_21")

# Replace the geometry column in result_data with the geometry from 1996
result_data$geometry <- coalesce(result_data$geometry, result_data$geometry.y)

# Drop the extra geometry_1996 column since I have already merged the values
result_data <- result_data %>%
    dplyr::select(c(-geometry.x,-geometry.y))

# Convert result_data back to an sf object
result_data_sf <- st_as_sf(result_data, crs = st_crs(panel_data_6year))

# Verify that it is sf object
class(result_data_sf)

# Drop rows with missing values from result_data_sf
result_data_sf <- result_data_sf %>%
    drop_na()

# Apply the cap to percentage variables, since they should be capped at 100
result_data_sf$per_owners <- pmin(result_data_sf$per_owners, 100)
result_data_sf$per_renters <- pmin(result_data_sf$per_renters, 100)
result_data_sf$per_mvd1yr <- pmin(result_data_sf$per_mvd1yr, 100)
result_data_sf$per_mvd5yr <- pmin(result_data_sf$per_mvd5yr, 100)
result_data_sf$per_visminority <- pmin(result_data_sf$per_visminority, 100)
result_data_sf$per_black <- pmin(result_data_sf$per_black, 100)
result_data_sf$per_asian <- pmin(result_data_sf$per_asian, 100)
result_data_sf$per_male <- pmin(result_data_sf$per_male, 100)
result_data_sf$per_female <- pmin(result_data_sf$per_female, 100)
result_data_sf$per_ages15_29 <- pmin(result_data_sf$per_ages15_29, 100)
result_data_sf$per_singlefather <- pmin(result_data_sf$per_singlefather, 100)
result_data_sf$per_singlemother <- pmin(result_data_sf$per_singlemother, 100)
result_data_sf$per_singleparent <- pmin(result_data_sf$per_singleparent, 100)
result_data_sf$per_bachplus <- pmin(result_data_sf$per_bachplus, 100)
result_data_sf$per_unemployed <- pmin(result_data_sf$per_unemployed, 100)
result_data_sf$per_immigrants <- pmin(result_data_sf$per_immigrants, 100)
result_data_sf$per_racialized_pop <- pmin(result_data_sf$per_racialized_pop, 100)
result_data_sf$per_indigenous <- pmin(result_data_sf$per_indigenous, 100)

#Save to directory
st_write(result_data_sf, "/Users/taylordomingos/Documents/research_projects/second_year_paper/raw_data/panel_data_annual.geojson")

```
